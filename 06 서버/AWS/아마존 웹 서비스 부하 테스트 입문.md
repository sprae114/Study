[성능 테스트 가이드 (velog.io)](https://velog.io/@sontulip/performance-test)
[부하테스트 (velog.io)](https://velog.io/@groovejumat/%EB%B6%80%ED%95%98%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%A5%BC-%ED%95%98%EA%B8%B0%EC%9C%84%ED%95%9C-2%EA%B0%80%EC%A7%80-%EB%8F%84%EA%B5%AC#locust-1)

----
# CHAPTER 2 웹 시스템 설계 방법
## 가용성이란?
시스템이 작동 가능한 상태, 즉 요청에 응답할 준비가 되어 있는 상태를 의미합니다. IT 서비스 관리(ITSM) 분야에서는 가용성을 "특정 시간 동안 시스템이 정상적으로 작동하고, 사용자가 필요할 때 접근할 수 있는 상태"로 정의합니다.

가용성은 보통 백분율로 표현되며, 이는 시스템이 얼마나 신뢰할 수 있는지를 나타내는 지표입니다. 예를 들어, 시스템의 가용성이 99.9%(일명 '세 개의 9')라면, 평균적으로 연간 약 8.76시간 동안만 시스템이 작동하지 않는다는 것을 의미합니다.


## 높은 가용성을 가진 시스템을 설계하는 방법은?
1) 시스템 이중화
![[Pasted image 20240301174342.png]]
이중화란 시스템의 **중요한 컴포넌트를 복제하여, 한 부분이 고장나더라도 시스템이 계속 작동**할 수 있도록 하는 전략입니다. 예를 들어, 데이터베이스 서버를 이중화하면 한 서버가 고장났을 때 다른 서버가 그 기능을 대신 수행할 수 있습니다. 

이중화된 시스템은 네트워크 지연(Latency)과 데이터 전송 능력(Throughput)이 허락되는 범위 내에서 지리적, 물리적으로 떨어진 장소에 설치해야함.

2) 시스템 확장
▶스케일 업
![[Pasted image 20240301174357.png]]
- 장점: 스케일 업은 **하드웨어의 성능을 향상**시키는 가장 직접적인 방법입니다. 이를 통해 시스템의 **처리 용량을 증가**시키고, 응답 시간을 줄일 수 있습니다. 또한, **추가적인 서버를 관리할 필요가 없으**므로 시스템 관리가 **비교적 간단**합니다.

- 단점: 스케일 업은 하드웨어의 물리적인 한계에 의해 제한됩니다. 즉, **특정 수준 이상으로 성능을 향상시키는 것이 어렵**습니다. 또한, 하드웨어를 업그레이드하는 데는 **높은 비용이 발생**하며, 업그레이드 과정에서 시스템을 중단해야 할 수도 있습니다.

▶스케일 아웃
![[Pasted image 20240301174421.png]]
- 장점: 스케일 아웃은 시스템에 **서버를 추가하여 처리 용량**을 늘리는 방법입니다. 이는 시스템의 가용성을 높이고, **하나의 서버가 고장나도 시스템 전체가 작동을 멈추지 않도록** 합니다. 또한, 수평적으로 확장 가능하므로 **하드웨어의 물리적 한계에 의해 제한받지 않습**니다.

- 단점: 스케일 아웃은 여러 서버를 관리해야 하므로 **시스템 관리가 복잡**해질 수 있습니다. 또한, 서버 간의 **데이터 일관성**을 유지하는 데 어려움이 있을 수 있습니다.

3) 클라우드가 보증하는 서비스 사용
아마존에서 제공하는 서비스인 Route 54(DNS 제공 서비스), CloudFront(CDN 제공 서비스), Elastic Load Balancing(로드 밸런싱 제공 서비스), S3(스토리지 제공 서비스) 등.. 을 이용해서 가용성을 높히자.


## 클라우드에서의 시스템 구축방법은?
#### EC2를 이용한 동적 콘텐츠 배포
![[Pasted image 20240301232210.png]]
- EC2 인스턴스 상에 웹 서버와 애플리케이션을 구축하고 로드 밸런스 아래에 배치하여 스케일 아웃 되도록 구성한다. 
- Auto Scaling Group 설정을 하여 부하에 따라 자동으로 서버 대수를 변경할 수 있도록 한다.
- Route 53과 ELB 모두 여러 데이터 센터를 사용하는 형태로 이중화되어 있다.


#### S3를 이용한 정적 콘텐츠 배포
![[Pasted image 20240301232237.png]]
- S3 자체로 콘텐츠를 HTTP(S)로 제공할 수 있는 서비스이다.
- 도메인명을 사용하기 위해 Route 53을 사용하고 콘텐츠 배포 성능을 위해 CloudFront를 같이 사용한다.
- Route 53과 CloudFront 모두 AWS가 확장성을 보장하는 서비스이다.


#### 동적 콘텐츠 + 정적 콘텐츠 배포
![[Pasted image 20240301232307.png]]
- CloudFront의 멀티 오리진기능을 활용하여 콘텐츠 경로에 따라 다른 위치에 저장 된 콘텐츠를 참고할 수 있다.
- 동적 콘텐츠와 정적 콘텐츠 문제를 분리하여 생각할 수 있어 부하 테스트 시 정적 콘텐츠에 대한 요청을 제외한 시나리오를 작성하여 동적 콘텐츠 부하 테스트에 집중할 수 있다.


#### RDS를 이용한 RDB 구축
![[Pasted image 20240301232418.png]]
- Multi-AZ 옵션을 사용하여 마스터 DB, 슬레이브 DB, DNS 서비스 모두 여러 데이터 센터를 사용하는 형태로 이중화 구성을 할 수 있다. 
- 참조계를 처리하는 슬레이브 DB는 데이터베이스 엔진 별로 리드 레플리카 수의 제한이 있지만, 그 범위 안에서는 쉽게 확장을 할 수 있다. 



# CHAPTER 3 부하 테스트 기본 지식
#### 클라우드에서의 부하 테스트 목적은?
1) 각 시스템의 응답 성능을 예측하기 위함.
2) 부하가 많이 발생할때 성능을 개선하기 위함.


## 부하 테스트에서의 시스템 성능 지표 용어는?
![[Pasted image 20240302045510.png]]
1. Throughput(처리량)
처리량은 **단위 시간당 시스템이 처리할 수 있는 작업의 수**를 나타냅니다. 일반적으로 초당 거래 수(Transactions Per Second, TPS) 또는 초당 요청 수(Requests Per Second, RPS) 등의 단위로 표현합니다. **더 높은 처리량은 더 많은 작업을 더 빠르게 처리할 수 있다**는 것을 의미합니다.

2. Latency(지연시간)
지연시간은 **특정 작업을 완료하는 데 걸리는 시간**을 나타냅니다. 일반적으로 밀리초(ms) 또는 마이크로초(μs) 단위로 표현합니다. 지연시간은 요청이 시스템에 도달한 시점부터 응답이 사용자에게 돌아올 때까지의 시간을 포함합니다. 더 낮은 지연시간은 더 빠른 응답 시간을 의미합니다.


## 시스템 성능 개선 기본 지식
#### Throughput 개선
![[Pasted image 20240302060340.png]]


#### Latency 개선
Latency는 '대기 시간을 포함한 각 하위 시스템 처리 시간의 총합이다. Latency를 개선하기 위해서는 '긴 처리 시간이 필요한 처리'에서 순차적으로 개선 사항이 없는지 확인해야한다.

1) 애플리케이션에서 많은 시간이 걸리는 비효율적인 알고리즘이나 필요 없는 I/O 발생
2) 데이터베이스에서 인덱스 부족 등의 현상
3) Throughput 한계에 도달하면 대기 시간이 길어지는 경우


## 좋은 부하 테스트에 대한 지표
1) 테스트 대상 시스템은 부하가 집중되고 있는 상태 (해당 시스템 부하 테스트 가능)
2) 병목 지점을 확인한 상태 (어느 지점이 과부하 되어있는지 확인 가능)

  
# CHAPTER 4 부하 테스트 도구 
## 부하 테스트에서 사용하는 3가지 도구
![[Pasted image 20240302061126.png]]
1) 부하 테스트 도구 : 시스템에 부하를 주는 도구로, 많은 Http(s) 요청으로 인해 시스템에 부하를 준다.
2) 모니터링 도구 : 시스템 리소스 사용률을 가시화해주는 도구로, 시스템 리소스(CPU, 메모리, 스토리지 등등..) 감시함.
3) 프로파일링 도구 : 미들웨어나 애플리케이션 내부 동작을 분석하고 가시화해주는 도구로, 애플리케이션(Spring, MySQL 등등..) 감시함.


## 부하 테스트 도구 용어 정리
#### 클라이언트
HTTP 요청을 동시에 1개만 줄 수 있는 요청 생성기

#### 클라이언트 동시 가동수
테스트 시작 후에 테스트 도구에서 사용할 수 있는 클라이언트 수

#### Ramp-up 기간
테스트 시작 후 모든 클라이언트를 기동하기까지의 준비 기간

#### 시나리오
클라이언트별로 설정된 HTTP 요청 생성 패턴

#### 시나리오 실행 횟수
클라이언트가 시나리오에 따라 요청을 보내는 횟수

#### Throughput 
시스템이 시간당 처리할 수 있는 요청 수

#### Latency 
테스트 도구가 요청을 보내고 응답을 받을 때까지의 시간


## 부하 테스트 도구에 필요한 조건은?
1) 요청을 정확하게 시뮬레이션한다.
2) 부하 정도를 조정 가능해야 한다.
3) 대상 시스템에 충분한 부하를 발생시켜야 한다.
4) 부하 테스트 도구 · 설치·장소 및 가동 장소를 선택할 수 있어야 한다.


## 부하 테스트 흐름
![[Pasted image 20240302155600.png]]
(1) 부하 테스트 서버에서 HTTP 요청 생성  
(2) HTTP 요청이 네트워크로 이동  
(3) 로드 밸런서가 요청을 서버에 전달  
(4) HTTP 요청을 웹 서버가 받음  
(5) HTTP 응답을 웹 서버가 보냄  
(6) 로드 밸런서를 통해 외부로 나감  
(7) HTTP 응답이 네트워크로 이동  
(8) 부하 테스트 서버가 HTTP 응답 받음. 그 이후로 다시 (1)로 돌아감


## 부하 테스트 주의점
1. 부하 테스트 도구에서 보이는 Latency는 부하 테스트 대상 시스템의 **Latency와는 다르다.**
부하 테스트 도구에서 측정하는 지연시간(Latency)은 클라이언트(테스트 도구)가 요청을 보내고 응답을 받는 데 걸리는 전체 시간을 포함합니다. 따라서 이 지연시간은 실제 시스템의 작업 처리 시간만을 나타내는 것이 아니라, 여러 요인에 의해 영향을 받습니다. 그래서 각 시스템의 실제 Latency는 서버로그를 보거나 로드 밸런서에서 보인 Latency를 확인해야함.

2. 부하 테스트 도구의 클라이언트 동시 기동 수와 시스템에서 처리되는 **동시 처리 수는 다르다.**
부하 테스트 도구에서 설정하는 동시 사용자 수는 클라이언트가 동시에 요청을 보내는 수를 의미합니다. 하지만, 실제 시스템에서 한 번에 처리할 수 있는 요청의 수는 시스템의 처리 용량에 따라 다릅니다. 예를 들어, 100개의 요청을 동시에 보냈지만 시스템이 한 번에 처리할 수 있는 요청 수가 10개라면, 나머지 90개의 요청은 대기 상태가 될 것입니다.

3. 부하 테스트 도구의 클라이언트는 앞의 요청이 **완료되지 않으면 다음 요청을 생성하지 않는다.**
실제 사용자의 행동을 모방하는 방식으로, 한 사용자가 여러 작업을 동시에 처리하지 않는다는 가정 하에 동작합니다. 예를 들어, 웹 페이지 로딩이 완료되기 전에 다른 페이지를 요청하는 경우는 드뭅니다. 


## 부하테스트와 실 운영환경의 차이는?
1) 요청을 생성하는 서버 대수, 네트워크의 차이
![[Pasted image 20240302185232.png]]
- 부하 테스트는 일반적으로 **한정된 수로 요청을 보내 부하 테스트 서버에 과부하가 발생**합니다. 반면 실 운영 환경에서는 수 많은 사용자가 다양한 위치와 조건에서 요청을 보냅니다. 
- 부하 테스트는 **테스트 환경의 네트워크에 집중**되지만, 실 운영 환경에서는 네트워크의 상태가 시간과 위치에 따라 변해 처리가 분산된다.

2) 요청을 보내는 서버와 엔드포인트의 차이
![[Pasted image 20240302185714.png]]
- 부하 테스트 환경에서는 **테스트 도구가 요청을 생성하고, 지정된 엔드포인트**에 보냅니다. 반면 실 운영 환경에서는 사용자의 디바이스나 애플리케이션에서 요청이 생성되고, 여러 엔드포인트에 분산되어 보내집니다.

3) 동시 요청수의 차이
![[Pasted image 20240302185929.png]]
- 부하 테스트 환경에서는 **동시 요청 수를 사전에 설정하고 이를 일정하게 유지**합니다. 하지만 실 운영 환경에서는 사용자의 행동 패턴과 시간대에 따라 동시 요청 수가 크게 변할 수 있습니다.

4) 일부 느린 처리가 전체 Throughput에 미치는 영향의 차이
![[Pasted image 20240302190148.png]]
- 부하 테스트 환경에서는 **일부 응답에 시간이 걸리면 전체가 대기하여 부하 상태**로 된다. 반면에 실 운영 환경에서는 일부 응답이 시간이 걸린다고해도 해당 사용가자 아니라면 영향받지 않는다.

## 부하 테스트 도구 종류
#### Apache Bench
- 단일 URL 부하 테스트는 간단히 가능
- POST/PUT 부하 테스트 가능(DELETE 불가능)
- 요청별로 파라미터 변경 불가
- 시나리오 테스트 불가
- 부하 테스트 서버의 CPU 코어 1개만 사용


#### Apache JMeter
- Apache Bench에서 할 수 없는 DELETE 테스트 가능
- 요청 별로 동적 파라미터 변경 가능
- 복수의 URL에 시나리오 기반의 복잡한 부하 테스트 가능
- 시나리오는 XML을 사용하지만, GUI로 사용할 수 있고 비교적 직관적인 시나리오 작성 가능
- Proxy Recorder를 사용한 시나리오 작성도 가능
- 부하 테스트 결과 출력 기능이 다양
- 복수의 서버를 연계하여 비교적 고부하 테스트 가능
- HTML 콘텐츠는 콘텐츠 내에서 필요한 여러 가지 정적 리소스를 동시에 확인할 수 있는 테스트 가능


#### Locust
- 시나리오를 파이썬 스크립트로 작성할 수 있어 유연한 시나리오를 만들 수 있다.
- 테스트 시나리오가 스크립트로 되어 있어 소스 코드로 관리할 수 있다.
- 필요한 서버 리소스가 작으므로 작은 크기의 부하 테스트 서버로 테스트할 수 있다.
- 테스트 결과 리포트가 간단하다.

## 각 하위 시스템의 상세 모니터링 도구
![[Pasted image 20240302191929.png]]

#### top 명령어
[[Linux] top 명령어로 서버의 상태 파악하기 (tistory.com)](https://sabarada.tistory.com/146)
많은 Linux계 OS에는 기본으로 제공되는 명령어로 시스템 전체와 **프로세스별 CPU와 메모리 사용량** 등을 볼 수 있다. **실시간**으로 볼 수 있어 부하 테스트 시에 유용하게 사용된다.

▶ 사용방법
```BASH
top
```

▶ 결과
![[Pasted image 20240302192155.png]]
- Cpu(s) : CPU의 사용률을 보여줍니다. 사용자 프로세스(user), 시스템 프로세스(system), 대기 중인 I/O(wait), 아무 것도 하지 않고 있는 시간(idle) 등을 볼 수 있습니다.

- Mem: 메모리 사용량을 보여줍니다. 전체 메모리(total), 사용 중인 메모리(used), 사용 가능한 메모리(free), 버퍼로 사용된 메모리(buffers) 등의 정보를 제공합니다.


#### netstat 명령어
[[네트워크] Linux 환경에서 네트워크 관련 트러블슈팅을 위한 기본 command 가이드 (tistory.com)](https://co-no.tistory.com/m/123?category=1069105)
네트워크 연결, 라우팅 테이블, 인터페이스 통계 등 **네트워크 관련 정보**를 보여주는 도구입니다.

▶ 사용방법
```BASH
netstat -nato
```

▶ 결과
![[Pasted image 20240303055118.png]]
- Proto: 연결의 프로토콜을 나타냅니다. (TCP, UDP 등)
- Local Address: 로컬 시스템의 IP 주소와 포트 번호를 나타냅니다.
- Foreign Address: 원격 시스템의 IP 주소와 포트 번호를 나타냅니다.
- State: 연결 상태를 나타냅니다. (LISTEN, ESTABLISHED, CLOSE_WAIT 등)



#### AWS의 CloudWatch 활용
[(15) AWS의 눈 - Cloud Watch - YouTube](https://www.youtube.com/watch?v=jGryI-hBA38&ab_channel=%EC%83%9D%ED%99%9C%EC%BD%94%EB%94%A9)
![[Pasted image 20240303055630.png]]
AWS에서 제공하는 **모니터링 서비스로, 애플리케이션, 로그, 지표 및 리소스에 대한 상세한 보기를 제공**합니다. 이를 통해 사용자는 시스템의 성능을 향상시키고 리소스를 최적화하며, 애플리케이션을 효과적으로 실행하고, 전반적인 운영 상태를 파악할 수 있습니다.

CloudWatch의 주요 기능은 
1. **대시보드**: 사용자 정의 대시보드를 생성하여 필요한 모든 지표를 한 눈에 볼 수 있습니다.
2. **알람**: 특정 지표가 설정된 임계값을 초과하거나 미달할 경우 알림을 받을 수 있습니다.
3. **이벤트**: AWS 리소스에서 발생하는 변화를 감지하고, 이를 기반으로 자동으로 AWS Lambda 함수나 다른 리소스를 트리거할 수 있습니다.
4. **로그**: 애플리케이션과 리소스에서 발생하는 로그를 수집, 추적, 분석할 수 있습니다.
5. **지표**: AWS 리소스와 애플리케이션에서 제공하는 지표를 수집하고 추적할 수 있습니다. 이를 통해 시스템의 전반적인 성능과 운영 상태를 파악할 수 있습니다.


# CHAPTER 5 부하 테스트 계획
## 부하 테스트 대상 시스템
![[Pasted image 20240303194031.png]]

- MySQL은 RDS라는 AWS에서 제공하는 서비스를 이용한다.
- MySQL에는 MulAZ 옵션을 설정하고 Active-Standby 형태로 이중화한다.
- DNS는 AWS가 제공하는 Route 53 서비스를 사용한다.
- 로드 밸런서는 ELB를 사용한다.
- 웹 서버는 데이터 센터에 해당되는 가용 영역(Availability Zone(AZ))을 이용하여 여러 대로 구성한다.
- 캐시 서버로는 AWS 서비스인 ElasticCache를 사용한다.
- 외부 서비스와는 HTTP, HTTPS로 통신한다.


## 부하 테스트 계획 준비
#### 조건 정리
1) 테스트 대상 시스템 범위
- 품질을 보증하는 범위를 명확하게 정의한다.

2) 데이터 양
- 부하 테스트 때 스토리지에 저장된 데이터 건수와 크기를 결정한다.
- 서비스 이용자 수, 예상 사용자 행동, 사용 기간 등을 통해서 계산한다. 

3) 외부 시스템 Latency, 사용할 시스템 제약
- 사용할 외부 시스템이라면 그 시스템의 Throughput와 Latency를 파악한다. 
- 최대 가능 동시 접속 수와 시간당 호출 횟수 제한 등의 제약이 있을 수 있다. 
- 외부 시스템과 통합이 어려운 경우 어떻게 처리할 것인지(더미 서버에 접속한 다. 일체 접속하지 않는다 등)를 정의한다.

4) 지속적인 성능 유지 기간
- X시간 이상 지속해서 성능을 유지할 것' 등과 같은 기간을 결정한다.
- 최종적으로 목푯값에 대해 기간 성능을 유지할 필요가 있다.

5) 부하를 주는 방법
- 어떤 네트워크에서 부하를 줄 것인지 
- HTTPS를 사용할지

6) 그 외에 조건
- 서버에 같이 동작하고 있는 다른 시스템에 영향을 주지 않을지를 확인한다.
- 일정 제약 및 환경적 제약을 확인한다.
- 이외 서비스 환경과 테스트 환경과의 차이에 따른 영향도 확인한다.


#### 목푯값 설정
![[Pasted image 20240303222326.png]]
1) Latency 목푯값
지연 시간은 사용자가 요청을 보내고 응답을 받기까지의 시간을 말합니다. 이 값은 가능한 한 낮아야 합니다. 일반적으로 웹 애플리케이션의 경우, 사용자 응답 시간이 200~300ms 이내라면 사용자는 이를 즉각적인 반응으로 느낄 수 있습니다. 

2) Throughput 목푯값
최대 RPS에 안전계수로 2~3배 곱한 숫자를 Throughput의 목푯값으로 설정한다.
![[Pasted image 20240303223027.png]]

```
1일 사용자 수(명/일)×1인당 1일 평균 접속 수(회/명)=1일 총 접속 수(회/일)
1일 총 접속 수(회/일)/1일 초 수 86,400(초/일)=1일 평균 rps(회/초)
1일 평균 rps(회/초)×1일 평균 접속 수에 대한 최대 피크 때의 배율=최대 rps(회/초)
```

예를 들어, 다음과 같은 상황이면
- DAU = 5만명
- 1명당 평균 접속 수 = 20회
- 1일 평균 접속 수에 대한 최대 피크 때의 배율 = 3배
- 안전 계수 = 3
```
50,000 × 20 ÷ 86,000 × 3 × 3 ≓ 104 RPS
```


#### 사용할 도구 준비
- 간편하게 사용하는 도구(Apache Bench, JMeter 등)
- 많은 테스트 시나리오로 테스트할 수 있는 도구(JMeter, Locust 등)
- 많은 부하를 줄 수 있는 도구(tsung, JMeter, Locust 등)


## 부하 시나리오
시스템에 부하를 많이 주고 Latency에 악영향을 줄 수 있는 원인에 대해서 중점적으로 부하 테스트를 해야함.

#### 접속 빈도가 높은 페이지
특히 동시 접속자 수가 많아질 때 서버의 성능을 확인해야 합니다. 이 페이지가 서버에 과부하를 주지 않는지 확인해야 합니다.

▶ 접속 빈도가 높은 페이지(요청) 예
- 홈페이지, 로그인 페이지, 검색 페이지


#### 서버 리소스 소비량이 높을 것으로 예상되는 페이지
이 페이지는 CPU, 메모리, 디스크 I/O 등 서버 리소스를 많이 사용할 가능성이 있습니다. 이 경우, 해당 페이지에 대한 부하 테스트를 통해 서버 리소스의 사용량을 확인하고, 필요한 경우 최적화를 수행해야 합니다.

▶ CPU 리소스를 소비하기 쉬운 페이지(요청) 예
- 사용자가 입력한 비밀번호 암호화나 인증을 하는 페이지
- 이미지, 동영상 변환을 하는 페이지
- 파일 압축과 풀기를 하는 페이지

▶ 네트워크 대역을 소비하기 쉬운 페이지(요청) 예
- 응답 콘텐츠 크기가 큰 페이지
- 이미지, 동영상 업로드와 다운로드를 하는 페이지

▶ 디스크 I/O를 소비하기 쉬운 페이지(요청) 예
- 로그가 많은 페이지
- 동적 파일 내에 검색 등을 하는 페이지


#### DB를 참조하는 페이지
SQL 쿼리의 성능을 확인하고, 인덱싱, 쿼리 최적화 등을 통해 데이터베이스 성능을 향상시키는 것이 중요합니다.


▶ 여러 사용자가 같은 리소스를 참고하고 같은 응답을 반환하는 페이지
특정 리소스에 대해 참고가 집중되었을 때 계속 응답을 주기 위해서이다. 이때, 캐시를 사용하는 등의 대책을 세워야 한다.

- 마스터 데이터 형태의 참고 페이지
- 모든 인원이 최신 사용자 게시물을 참고하는 페이지

▶ 리소스 전체를 검색하고 그 결과를 보여주는 페이지
리소스 전체 검색은 DB에 부하를 주기 쉽고 병목 구간이 되기 쉽다.

- 포인트 랭킹을 실시간으로 표시하는 페이지
- 사용자 게시판 최신순으로 정렬하여 표시하는 페이지
- 자신과 비슷한 사용자 검색, 표시 페이지

▶ 접속하는 사용자별로 다른 리소스를 참고하고 개별적으로 응답을 보여주는 페이지 
사용자에 대한 트랜잭션 데이터 참고를 말한다. 사용자 트렌잭션 데이터는 데이터 총량이 커지기 쉬워 캐시를 사용하는 것도 어려운 페이지다.

- 사용자별 마이페이지
- 사용자 속성에 있는 결과를 표시하는 페이지
- 사용자가 소유한 타임라인


#### DB를 갱신하는 페이지
이 페이지는 데이터의 일관성과 무결성에 영향을 미칠 수 있습니다. 트랜잭션 처리 성능을 확인하고, 롤백, 병렬 처리 등의 메커니즘을 통해 데이터의 일관성을 유지하는 것이 중요합니다.


▶ 여러 사용자가 같은 리소스를 갱신하는 페이지
많은 사람이 같은 리소스를 갱신하는 경우 해당 리소스에 락이 걸리는 경우가 있다.

- 상품 재고 관리 처리
- 경매 입찰 처리

▶ 사용자별로 다른 리소스를 갱신하는 페이지
갱신 대상 리소스가 분산되어 있을 때도 DB 구성의 문제로 일부 데이터가 락이 걸릴 가능성이 있다. 하지만 락이 걸리지 않았다고 해도 DB 갱신 능력을 초과했을 가능성이 있다.

- 댓글 페이지
- 방명록 기능
- 로그인 세션 발행 페이지


#### 외부 시스템과 통신하는 페이지
외부 시스템 리소스를 포함하면 파일보다 압도적으로 느려진다. 그래서 네트워크 성능을 확인하고, 외부 시스템과의 통신 효율을 최적화하는 것이 중요합니다.

▶페이지(요청) 예
- 공유 캐시 서버를 사용하는 페이지
- 로그를 외부 시스템에 전송하는 페이지
- SNS(Simple Notification Service)/SQS(Simple Queue Service) 등의 시스템 이용 
- 그 외에 외부 API 통신이 발생하는 페이지


# CHAPTER 7 부하 테스트 실행 1(테스트 실행과 병목 현상 확인)

## 부하 테스트 결과의 타당성 평가
![[Pasted image 20240304015225.png]]

```
테스트 클라이언트 수가 100이었을때

Throughput : 1,000rps
Latency : 200ms
```


## 전체적인 시스템 문제가 될수 있는 부분
![[Pasted image 20240304015457.png]]


## 단계에 따른 부하 테스트
#### 도구와 환경의 검증 웹 
![[Pasted image 20240304020324.png]]

#### 프레임워크 검증 
![[Pasted image 20240304020340.png]]


#### 참조계 성능 검증
![[Pasted image 20240304020402.png]]


#### 갱신계 성능 검증
![[Pasted image 20240304020414.png]]


#### 외부 서비스 연동 성능 검증
![[Pasted image 20240304020442.png]]


#### 시나리오 테스트
![[Pasted image 20240304020455.png]]

#### 스케일 업/아웃 테스트 준비
![[Pasted image 20240304020510.png]]

#### 스케일 업/아웃 테스트(단계 1~6 회귀 테스트)
![[Pasted image 20240304020532.png]]

![[Pasted image 20240304020551.png]]

![[Pasted image 20240304020804.png]]

![[Pasted image 20240304020820.png]]
![[Pasted image 20240304020831.png]]

#### 한계 성능 테스트(단계 1~6 회귀 테스트)
![[Pasted image 20240304021109.png]]

7.2 단계 1: 도구와 환경 검증 161  
7.2.1 대상 시스템 161  
7.2.2 Plan 162  
7.2.3 Do 163  
7.2.4 Check 163  
7.2.5 Action 164  
7.3 단계 2: 웹 프레임워크 검증 165  
7.3.1 대상 시스템 165  
7.3.2 Plan 166  
7.3.3 Do 166  
7.3.4 Check 166  
7.3.5 Action 167  
7.4 단계 3: 조회 성능 검증 167  
7.4.1 대상 시스템 167  
7.4.2 Plan 168  
7.4.3 Do 169  
7.4.4 Check 169  
7.4.5 Action 169  
7.5 단계 4: 갱신 성능 검증 170  
7.5.1 대상 시스템 170  
7.5.2 Plan 171  
7.5.3 Do 171  
7.5.4 Check 171  
7.5.5 Action 172  
7.6 단계 5: 외부 서비스 연동 성능 검증 173  
7.6.1 대상 시스템 173  
7.6.2 Plan 174  
7.6.3 Do 174  
7.6.4 Check 174  
7.6.5 Action 174  
7.7 단계 6: 시나리오 테스트 175  
7.7.1 Throughput 평가에 대해 175  
7.7.2 대상 시스템 176  
7.7.3 Plan 177  
7.7.4 Do 177  
7.7.5 Check 177  
7.7.6 Action 178  
7.8 단계 7: 스케일 아웃 테스트 준비 179  
7.8.1 대상 시스템 179  
7.8.2 Plan 180  
7.8.3 Do 180  
7.8.4 Check 180  
7.8.5 Action 180  
7.9 단계 8: 스케일 업/아웃 테스트(단계 1~6 회귀 테스트) 181  
7.9.1 대상 시스템 181  
7.9.2 스케일 업/스케일 아웃 예제 183  
7.9.3 Plan 186  
7.9.4 Do 187  
7.9.5 Check 187  
7.9.6 Action 187  
7.10 단계 9: 성능 한계 테스트(단계 1~6 회귀 테스트) 189  
7.10.1 대상 시스템 189  
7.10.2 Plan 190  
7.10.3 Do 190  
7.10.4 Check 191  
7.10.5 Action 191  
  
# CHAPTER 8 부하 테스트 실행 2(원인 분석과 시스템 개선 작업)
8.1 시스템 병목 확인 194  
8.2 부하 테스트 도구 병목 원인과 대책 195  
8.2.1 서버 및 테스트 도구 설정 문제 196  
8.2.2 테스트 시나리오 문제 200  
8.2.3 부하 테스트 서버 성능 부족 200  
8.2.4 부하 테스트 서버 네트워크 문제 201  
8.2.5 참고표 202  
8.3 웹 서버 병목 원인과 대책 203  
8.3.1 운영체제와 미들웨어 설정 문제 203  
8.3.2 웹 프레임워크 문제 205  
8.3.3 애플리케이션 문제 208  
8.3.4 서버 리소스 성능 부족 209  
8.3.5 참고표 210  
8.4 캐시 서버 병목 원인과 대책 214  
8.4.1 캐시 사용 방법 문제 215  
8.4.2 서버 리소스 부족 215  
8.4.3 참고표 215  
8.5 DB 서버 병목 원인과 대책 218  
8.5.1 DB 설계 문제 218  
8.5.2 DB 사용 애플리케이션 문제 220  
8.5.3 서버 리소스 부족 222  
8.5.4 참고표 224  
8.6 외부 서비스 병목 원인과 대책 231  
8.6.1 외부 시스템과 연동 방법 문제 231  
8.6.2 외부 시스템 성능 문제 233  
8.6.3 참고표 234  
  
# CHAPTER 9 부하 테스트 보고서 작성 239  
9.1 부하 테스트 최종 확인 240  
9.2 목푯값에 맞춘 적정한 구성 선정 241  
9.2.1 시스템 여유 리소스 확보 방안 242  
9.3 부하 테스트 보고서 작성 242  
9.3.1 보고서 필요 항목 242  
9.3.2 부하 테스트 보고서에 시스템 모니터링 데이터를 넣으면 생기는 문제 243  
9.4 요약 244  
  
CHAPTER 10 부하 테스트에 대한 실제 사례 245  
10.1 이 장에서 테스트하는 시스템 246  
10.1.1 애플리케이션 기능 요건 246  
10.1.2 시스템 요건 247  
10.1.3 시스템 설계 247  
10.1.4 부하 테스트 전제 조건 254  
10.2 JMeter+Xhprof로 PHP 애플리케이션 부하 테스트 사례 257  
10.2.1 부하 테스트 계획 수립 257  
10.2.2 테스트 실행 1: 도구와 웹 프레임워크 검증(테스트 시작) 261  
10.2.3 테스트 실행 2: 시나리오 테스트(테스트 실행) 279  
10.2.4 테스트 실행 3: 스케일 업/아웃 테스트(확장에 대한 한계) 293  
10.2.5 테스트 실행 4: 성능 한계 테스트(성능 한계 개선) 313  
10.2.6 적정한 구성 선정과 테스트 보고서 320  
10.3 Locust+New Relic으로 Node.js 애플리케이션 부하 테스트 사례 329  
10.3.1 1일 차 전반: 도구와 환경 검증 332  
10.3.2 1일 차 후반: 애플리케이션 시스템 전체 검증 339  
10.3.3 2일 차 전반: 애플리케이션 시스템 전체 검증(1일 차에 이어 계속) 351  
10.3.4 2일 차 전반: 확장성 검증(2배 확장) 355  
10.3.5 2일 차 후반: 확장성 검증 ? 웹 서버 확장 시 발생하는 병목 현상은? 362  
10.3.6 3일 차: 최소 구성에 대한 검증 375  
  
CHAPTER 11 부록 I(용어 설명 외) 393  
11.1 용어 설명 394  
11.1.1 일반 용어 394  
11.1.2 AWS 용어, 아이콘 설명 396  
11.2 JMeter 시나리오 설명 401  
11.2.1 Thread Group 생성 402  
11.2.2 Simple Controller를 사용한 그룹화 403  
11.2.3 Dummy user_id 생성 404  
11.2.4 사용자 정의 변수 사용 405  
11.2.5 HTTP Request 실행 406  
11.2.6 HTTP 응답으로부터 user_id 수집 407  
11.2.7 시나리오 일부를 ?% 확률로 실행 410  
11.2.8 시나리오 일부를 ?회 반복 411  
11.2.9 통계 보고서 표시 412  
11.3 Locust 시나리오 설명 413  
11.3.1 Locust 기본 413  
11.3.2 10장에서의 시나리오 417  
11.4 부하 테스트의 문제 설명 423  
  
CHAPTER 12 부록 II(AWS 로드 테스팅) 431